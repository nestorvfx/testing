import React, { useState, useEffect, useRef } from 'react';
import { TouchableOpacity, Text, StyleSheet, View, ActivityIndicator, Alert, Platform } from 'react-native';
import { Ionicons } from '@expo/vector-icons';
import VoiceService from '../../services/voiceService';
import { testMicrophone, fixAndroidAudioIssues } from '../../services/androidAudioFix';

// Simple console logger
const logDebug = (message) => {
  if (__DEV__) console.debug(`[VoiceButton] ${message}`);
};

const logInfo = (message) => {
  if (__DEV__) console.info(`[VoiceButton] ${message}`);
};

const logError = (message) => {
  console.error(`[VoiceButton] ERROR: ${message}`);
};

const logWarn = (message) => {
  console.warn(`[VoiceButton] WARN: ${message}`);
};

const logEvent = (event) => {
  if (__DEV__) console.info(`[VoiceButton] Event: ${event}`);
};

const VoiceButton = ({ onSpeechResult, isActive, onToggleActive, isAnalyzing = false }) => {
  // State
  const [isListening, setIsListening] = useState(false);
  const [volume, setVolume] = useState(0);
  const [inCooldown, setInCooldown] = useState(false);
  const [errorMessage, setErrorMessage] = useState('');
  const [isTesting, setIsTesting] = useState(false);
  
  // Track speech text with a ref to avoid state update timing issues
  const speechTextRef = useRef('');
  
  // Track errors and cooldown
  const errorCountRef = useRef(0);
  const cooldownTimerRef = useRef(null);
  const consecutiveErrorsRef = useRef(0);
  
  // Start voice recognition on component mount if active
  useEffect(() => {
    // Check if microphone is available or help user with setup
    const checkVoiceAvailability = async () => {
      try {
        logDebug('Checking voice recognition availability');
        const available = await VoiceService.requestMicrophonePermission();
        logInfo(`Voice recognition available: ${!!available}`);
        
        if (available && Platform.OS === 'android') {
          // Preemptively try to fix common Android audio issues
          try {
            logDebug('Preemptively fixing audio issues');
            const result = await fixAndroidAudioIssues();
            logInfo(`Audio fix result: ${result.message}`);
          } catch (err) {
            logError(`Failed to apply audio fixes: ${err.message}`);
          }
        }
      } catch (e) {
        logError('Error checking voice availability', e.message);
      }
    };
    
    checkVoiceAvailability();
    
    return () => {
      cleanupVoiceService();
    };
  }, []);
  
  // Effect to handle setting up the voice service
  useEffect(() => {
    logDebug('Setting up voice recognition service');
    
    if (isActive) {
      startVoiceRecognition();
    } else {
      stopVoiceRecognition();
    }
    
    return () => {
      cleanupVoiceService();
    };
  }, [isActive]);
  
  // Clean up voice service
  const cleanupVoiceService = async () => {
    try {
      if (isListening) {
        logDebug('Cleanup: stopping listening');
        await VoiceService.stop();
        setIsListening(false);
      }
      
      logDebug('Cleanup: destroying voice service');
      // Don't call destroy() as it might interfere with future instances
      // Just make sure we're stopped
    } catch (error) {
      // Ignore cleanup errors
    }
  };
  
  // Toggle voice recognition
  const toggleVoiceRecognition = async () => {
    if (inCooldown || isAnalyzing) {
      return;
    }
    
    if (isActive) {
      // Already active, toggle off
      onToggleActive();
      await stopVoiceRecognition();
    } else {
      // Not active, toggle on
      onToggleActive();
      // Voice recognition will be started by the effect
    }
  };
  
  // Start voice recognition
  const startVoiceRecognition = async () => {
    if (isListening || inCooldown || isAnalyzing) {
      return;
    }
    
    try {
      // Reset state for new session
      setErrorMessage('');
      speechTextRef.current = '';
      
      // Set up event handlers
      VoiceService.onSpeechStart = handleSpeechStart;
      VoiceService.onSpeechEnd = handleSpeechEnd;
      VoiceService.onSpeechResults = handleSpeechResults;
      VoiceService.onSpeechPartialResults = handleSpeechPartialResults;
      VoiceService.onSpeechError = handleSpeechError;
      VoiceService.onSpeechVolumeChanged = handleVolumeChanged;
      
      // Start listening
      await VoiceService.start('en-US');
      setIsListening(true);
    } catch (error) {
      handleSpeechError({
        error: 'start_error',
        message: error.message
      });
    }
  };
  
  // Stop voice recognition
  const stopVoiceRecognition = async () => {
    if (!isListening) {
      return;
    }
    
    try {
      await VoiceService.stop();
    } catch (error) {
      // Ignore stop errors
    } finally {
      setIsListening(false);
      setVolume(0);
    }
  };
  
  // Get background color based on state
  const getBackgroundColor = () => {
    if (inCooldown) {
      return styles.cooldown.backgroundColor;
    }
    
    if (isAnalyzing) {
      return styles.disabled.backgroundColor;
    }
    
    if (isListening) {
      // If we're actively listening, use volume to adjust intensity
      // Map volume from 0-10 to a color intensity
      const baseColor = 29; // hue value for green
      const saturation = Math.min(100, 60 + volume * 4); // increase saturation with volume
      const lightness = Math.max(25, 50 - volume * 2); // decrease lightness with volume
      return `hsl(${baseColor}, ${saturation}%, ${lightness}%)`;
    }
    
    if (isActive) {
      return styles.active.backgroundColor;
    }
    
    return styles.button.backgroundColor;
  };
  
  // Test microphone functionality
  const handleLongPress = async () => {
    if (inCooldown || isAnalyzing || isTesting) {
      return;
    }
    
    setIsTesting(true);
    
    try {
      // Stop current recognition if active
      if (isListening) {
        await stopVoiceRecognition();
      }
      
      // Test microphone
      const testResult = await testMicrophone();
      
      // Show status to user
      if (testResult.working) {
        Alert.alert("Microphone Test", "Microphone is working correctly.");
      } else {
        Alert.alert(
          "Microphone Test Failed",
          `Reason: ${testResult.reason}\n${testResult.error || ''}`,
          [
            { text: "OK" },
            { 
              text: "Try to Fix",
              onPress: async () => {
                const fixResult = await fixAndroidAudioIssues();
                Alert.alert(
                  "Fix Result",
                  fixResult.fixed 
                    ? "Audio system fixed successfully! Try voice recognition again."
                    : `Failed to fix: ${fixResult.message}`
                );
              }
            }
          ]
        );
      }
    } catch (error) {
      Alert.alert("Microphone Test Error", error.message);
    } finally {
      setIsTesting(false);
      
      // Restart recognition if it was active
      if (isActive) {
        await startVoiceRecognition();
      }
    }
  };
  
  // Event Handlers
  const handleSpeechStart = (e) => {
    logEvent('onSpeechStart');
    setIsListening(true);
  };
  
  const handleSpeechEnd = (e) => {
    logEvent('onSpeechEnd');
    setIsListening(false);
    setVolume(0);
  };
  
  const handleSpeechResults = (results) => {
    // Ensure results exist and have values
    if (!results || !results.value || results.value.length === 0) {
      logWarn('Received empty speech results');
      return;
    }
    
    // Get recognized text
    const recognizedText = results.value[0] || '';
    
    // Update ref
    speechTextRef.current = recognizedText;
    
    // Handle finalized results
    if (results.isFinal) {
      logInfo(`Received final speech result: "${recognizedText}"`);
      
      // Reset error count if we got a successful result
      consecutiveErrorsRef.current = 0;
      
      // If we have a text and a callback, send it
      if (recognizedText && onSpeechResult) {
        logDebug('Processing final speech result');
        onSpeechResult(recognizedText, true, volume);
      }
    }
  };
  
  const handleSpeechPartialResults = (results) => {
    // Safety check
    if (!results || !results.value || results.value.length === 0) {
      return;
    }
    
    // Get partial text
    const partialText = results.value[0] || '';
    
    // Update ref
    speechTextRef.current = partialText;
    
    // If we have text and a callback, send the partial result
    if (partialText && onSpeechResult && !results.isFinal) {
      logDebug(`Partial speech result: "${partialText}"`);
      onSpeechResult(partialText, false, volume);
    }
  };
  
  const handleVolumeChanged = (e) => {
    if (e && typeof e.value !== 'undefined') {
      // Scale volume to 0-10 range
      const volumeLevel = Math.min(10, Math.floor(e.value * 10));
      setVolume(volumeLevel);
    }
  };
  
  const handleSpeechError = (error) => {
    const errorMessage = error?.message || 'Unknown speech recognition error';
    
    // Increment consecutive errors counter
    consecutiveErrorsRef.current += 1;
    
    // Update state
    setErrorMessage(errorMessage);
    setIsListening(false);
    
    // Log the error
    logError(`Speech recognition error: ${errorMessage}`);
    
    // Implement adaptive backoff for errors
    const maxBackoff = 10000; // 10 seconds
    const baseBackoff = 1000; // 1 second
    const backoffTime = Math.min(maxBackoff, baseBackoff * Math.pow(1.5, consecutiveErrorsRef.current - 1));
    
    logInfo(`Setting error cooldown: ${backoffTime}ms, consecutive errors: ${consecutiveErrorsRef.current}`);
    
    // Set cooldown and auto-restart if errors are not too many
    setInCooldown(true);
    
    if (consecutiveErrorsRef.current < 3) {
      logInfo('Auto-restarting speech recognition after error');
      cooldownTimerRef.current = setTimeout(() => {
        setInCooldown(false);
        if (isActive) startVoiceRecognition();
      }, backoffTime);
    } else {
      logWarn(`Too many errors (${consecutiveErrorsRef.current}), delaying restart`);
      
      // If we've had many errors, give a longer timeout then try one more time
      cooldownTimerRef.current = setTimeout(() => {
        setInCooldown(false);
        if (isActive && consecutiveErrorsRef.current < 5) {
          logInfo('Final restart attempt after multiple errors');
          startVoiceRecognition();
        } else {
          // Too many consecutive errors, give up and let user restart manually
          consecutiveErrorsRef.current = 0;
        }
      }, backoffTime * 2);
    }
  };
  
  // Cleanup timers
  useEffect(() => {
    return () => {
      if (cooldownTimerRef.current) {
        clearTimeout(cooldownTimerRef.current);
      }
    };
  }, []);
  
  // Get status color and icon
  let statusColor = '#666';
  let micIconName = 'mic-outline';
  
  if (inCooldown) {
    statusColor = '#d9534f'; // Danger for cooldown
    micIconName = 'mic-off-outline';
  } else if (isAnalyzing) {
    statusColor = '#f0ad4e'; // Warning for analyzing
    micIconName = 'hourglass-outline';
  } else if (isListening) {
    statusColor = '#5cb85c'; // Success for listening
    micIconName = 'mic';
  } else if (isActive) {
    statusColor = '#5bc0de'; // Info for enabled but not listening
    micIconName = 'mic-outline';
  }
  
  return (
    <TouchableOpacity
      style={[
        styles.button,
        isAnalyzing && styles.disabled,
        inCooldown && styles.cooldown,
        isActive && !isListening && styles.active,
        isListening && styles.listening,
        { backgroundColor: getBackgroundColor() }
      ]}
      onPress={toggleVoiceRecognition}
      onLongPress={handleLongPress}
      delayLongPress={1000}
      disabled={isAnalyzing}
      activeOpacity={0.7}
    >
      {isTesting ? (
        <ActivityIndicator color="#ffffff" size="small" />
      ) : (
        <>
          <Ionicons name={micIconName} size={22} color="white" />
          
          {/* Volume indicator (dots) when listening */}
          {isListening && (
            <View style={styles.volumeContainer}>
              {[...Array(5)].map((_, i) => (
                <View 
                  key={i} 
                  style={[
                    styles.volumeDot,
                    { opacity: i <= volume / 2 ? 0.9 : 0.3 }
                  ]} 
                />
              ))}
            </View>
          )}
        </>
      )}
    </TouchableOpacity>
  );
};

const styles = StyleSheet.create({
  button: {
    width: 44,
    height: 44,
    borderRadius: 22,
    backgroundColor: 'rgba(52, 73, 94, 0.8)',
    justifyContent: 'center',
    alignItems: 'center',
    marginHorizontal: 6,
  },
  active: {
    backgroundColor: 'rgba(52, 152, 219, 0.8)',
  },
  listening: {
    backgroundColor: 'rgba(46, 204, 113, 0.8)',
  },
  disabled: {
    backgroundColor: 'rgba(149, 165, 166, 0.8)',
  },
  cooldown: {
    backgroundColor: 'rgba(231, 76, 60, 0.8)',
  },
  volumeContainer: {
    position: 'absolute',
    bottom: -10,
    flexDirection: 'row',
    justifyContent: 'center',
    width: '100%',
    height: 4,
  },
  volumeDot: {
    width: 4,
    height: 4,
    borderRadius: 2,
    backgroundColor: 'white',
    marginHorizontal: 1,
  },
});

export default VoiceButton;
