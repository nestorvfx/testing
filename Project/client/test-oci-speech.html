<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OCI Speech Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
        }
        .success {
            background-color: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        .error {
            background-color: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
        .info {
            background-color: #d1ecf1;
            color: #0c5460;
            border: 1px solid #bee5eb;
        }
        button {
            padding: 10px 20px;
            margin: 5px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            background-color: #007bff;
            color: white;
        }
        button:hover {
            background-color: #0056b3;
        }
        button:disabled {
            background-color: #ccc;
            cursor: not-allowed;
        }
        #transcription {
            border: 1px solid #ccc;
            padding: 10px;
            min-height: 100px;
            margin-top: 10px;
            white-space: pre-wrap;
        }
    </style>
</head>
<body>
    <h1>OCI Speech Service Test</h1>
    
    <div id="status" class="status info">
        Initializing...
    </div>
    
    <div>
        <button id="testAuth" onclick="testAuthentication()">Test Authentication</button>
        <button id="startListening" onclick="startListening()" disabled>Start Listening</button>
        <button id="stopListening" onclick="stopListening()" disabled>Stop Listening</button>
    </div>
    
    <div>
        <h3>Transcription Results:</h3>
        <div id="transcription"></div>
    </div>
    
    <div>
        <h3>Logs:</h3>
        <div id="logs" style="font-family: monospace; background: #f5f5f5; padding: 10px; max-height: 300px; overflow-y: auto;"></div>
    </div>

    <script>
        const AUTH_SERVER_URL = 'http://localhost:8450';
        let isListening = false;
        let webSocket = null;
        let sessionToken = null;
        let compartmentId = null;
        let region = null;
        
        function log(message, type = 'info') {
            const logs = document.getElementById('logs');
            const timestamp = new Date().toLocaleTimeString();
            logs.innerHTML += `[${timestamp}] ${message}\n`;
            logs.scrollTop = logs.scrollHeight;
            console.log(message);
        }
        
        function setStatus(message, type = 'info') {
            const status = document.getElementById('status');
            status.textContent = message;
            status.className = `status ${type}`;
        }
        
        async function testAuthentication() {
            try {
                setStatus('Testing authentication...', 'info');
                log('Fetching authentication token...');
                
                const response = await fetch(`${AUTH_SERVER_URL}/authenticate`);
                if (!response.ok) {
                    throw new Error(`Authentication failed: ${response.statusText}`);
                }
                
                const data = await response.json();
                sessionToken = data.token;
                compartmentId = data.compartmentId;
                
                log(`Authentication successful! Session ID: ${data.sessionId}`);
                log(`Compartment ID: ${compartmentId}`);
                setStatus('Authentication successful!', 'success');
                
                // Get region
                const regionResponse = await fetch(`${AUTH_SERVER_URL}/region`);
                const regionData = await regionResponse.json();
                region = regionData.region;
                log(`Region: ${region}`);
                
                document.getElementById('startListening').disabled = false;
                
            } catch (error) {
                log(`Authentication failed: ${error.message}`);
                setStatus(`Authentication failed: ${error.message}`, 'error');
            }
        }
        
        async function startListening() {
            if (isListening || !sessionToken) return;
            
            try {
                setStatus('Starting speech recognition...', 'info');
                log('Setting up WebSocket connection...');
                
                // Build WebSocket URL
                const baseUrl = `wss://realtime.aiservice.${region}.oci.oraclecloud.com/ws/transcribe/stream`;
                const params = new URLSearchParams({
                    'isAckEnabled': 'false',
                    'partialSilenceThresholdInMs': '0',
                    'finalSilenceThresholdInMs': '1000',
                    'stabilizePartialResults': 'NONE',
                    'shouldIgnoreInvalidCustomizations': 'false',
                    'languageCode': 'en-US',
                    'modelDomain': 'GENERIC',
                    'punctuation': 'NONE',
                    'encoding': 'audio/raw;rate=16000'
                });
                
                const websocketUrl = `${baseUrl}?${params.toString()}`;
                log(`Connecting to: ${websocketUrl}`);
                
                webSocket = new WebSocket(websocketUrl);
                
                webSocket.onopen = () => {
                    log('WebSocket connected, sending authentication...');
                    
                    const authMessage = {
                        authenticationType: "TOKEN",
                        token: sessionToken,
                        compartmentId: compartmentId
                    };
                    
                    webSocket.send(JSON.stringify(authMessage));
                };
                
                webSocket.onmessage = (event) => {
                    try {
                        const message = JSON.parse(event.data);
                        log(`Received: ${JSON.stringify(message)}`);
                        
                        if (message.event === "CONNECT") {
                            log('OCI Speech authentication successful!');
                            setStatus('Connected and listening...', 'success');
                            isListening = true;
                            document.getElementById('startListening').disabled = true;
                            document.getElementById('stopListening').disabled = false;
                            startAudioCapture();
                        } else if (message.event === "RESULT") {
                            handleTranscriptionResult(message);
                        } else if (message.event === "ERROR") {
                            log(`Speech service error: ${JSON.stringify(message)}`);
                            setStatus(`Speech service error: ${message.message || 'Unknown error'}`, 'error');
                        }
                    } catch (err) {
                        log(`Error parsing message: ${err.message}`);
                    }
                };
                
                webSocket.onerror = (error) => {
                    log(`WebSocket error: ${error}`);
                    setStatus('WebSocket connection error', 'error');
                };
                
                webSocket.onclose = (event) => {
                    log(`WebSocket closed: ${event.code} ${event.reason || ''}`);
                    isListening = false;
                    document.getElementById('startListening').disabled = false;
                    document.getElementById('stopListening').disabled = true;
                    setStatus('Connection closed', 'info');
                };
                
            } catch (error) {
                log(`Error starting speech recognition: ${error.message}`);
                setStatus(`Error: ${error.message}`, 'error');
            }
        }
        
        function stopListening() {
            if (webSocket) {
                log('Closing WebSocket connection...');
                webSocket.close();
            }
            if (window.audioContext) {
                window.audioContext.close();
            }
            isListening = false;
            document.getElementById('startListening').disabled = false;
            document.getElementById('stopListening').disabled = true;
            setStatus('Stopped listening', 'info');
        }
        
        function handleTranscriptionResult(message) {
            const transcriptions = message.transcriptions;
            if (transcriptions && transcriptions.length > 0) {
                const result = transcriptions[0];
                const transcriptionDiv = document.getElementById('transcription');
                
                if (result.isFinal) {
                    log(`Final: ${result.transcription}`);
                    transcriptionDiv.innerHTML += `<strong>${result.transcription}</strong> `;
                } else {
                    log(`Partial: ${result.transcription}`);
                    // Update partial result display
                    const partialSpan = document.getElementById('partial') || document.createElement('span');
                    partialSpan.id = 'partial';
                    partialSpan.style.color = '#666';
                    partialSpan.textContent = result.transcription;
                    
                    if (!document.getElementById('partial')) {
                        transcriptionDiv.appendChild(partialSpan);
                    }
                }
            }
        }
        
        async function startAudioCapture() {
            try {
                log('Requesting microphone access...');
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    } 
                });
                
                window.audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 16000
                });
                
                const source = window.audioContext.createMediaStreamSource(stream);
                const processor = window.audioContext.createScriptProcessor(4096, 1, 1);
                
                processor.onaudioprocess = (event) => {
                    if (!isListening || !webSocket || webSocket.readyState !== WebSocket.OPEN) {
                        return;
                    }
                    
                    const inputBuffer = event.inputBuffer.getChannelData(0);
                    const outputBuffer = new Int16Array(inputBuffer.length);
                    
                    // Convert Float32 to Int16
                    for (let i = 0; i < inputBuffer.length; i++) {
                        const sample = Math.max(-1, Math.min(1, inputBuffer[i]));
                        outputBuffer[i] = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
                    }
                    
                    webSocket.send(outputBuffer.buffer);
                };
                
                source.connect(processor);
                processor.connect(window.audioContext.destination);
                
                log('Audio capture started successfully!');
                
            } catch (error) {
                log(`Error starting audio capture: ${error.message}`);
                setStatus(`Microphone error: ${error.message}`, 'error');
            }
        }
        
        // Initialize
        setStatus('Ready to test OCI Speech integration', 'info');
        log('Test page loaded. Click "Test Authentication" to begin.');
    </script>
</body>
</html>
